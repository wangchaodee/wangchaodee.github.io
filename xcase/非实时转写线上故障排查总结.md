# 非实时转写线上故障排查总结

# 							——再次认识TCP四次挥手



## 1、故障起因

背景：转写服务之前平稳运行接近一年。

**2019-07-07**  

客户反映转写服务报大量的文件下载错误：

```text
result={'err_no':26634,'failed':'文件下载失败','ok':-1}
```



## 2、问题排查与初步解决

**2019-07-08**  

**原因分析**：

1. 由于服务器磁盘占满，导致从云存储下载音频文件失败；
2. 由于大量的错误日志记录，导致磁盘占满；
3. 由于大量的网络连接异常，导致大量的异常日志记录；
4. 查看部分日志，是连接流控服务时，产生大量网络异常。

**初步解决**：

为及时恢复转写服务，修改代码，屏蔽流控服务的调用；服务恢复正常。



## 3、再次爆发

**2019-07-14**  

客户反馈又有任务失败，日志报出文件上传失败，也就是连接云存储服务异常：

```text
com.iflytek.msp.lfasr.common.exception.LfasrException: 文件上传失败|upload slice fail
```



## 4、本质原因分析

经过前两次的故障，分析日志，其本质都是网络问题导致的；

无论是连接流控服务的网络异常，还是连接云存储服务的异常；

在日志中发现最根本性的错误：

```txt
java.net.ConnectException: Cannot assign requested address
```

也就是作为服务的客户端无法分配本地端口地址。



**wiki：**

```text
我们最熟知的端口，就是在启动服务端时，如tomcat的8080等；
但是当我们作为客户端去连接其他服务时，我们的操作系统会动态的分配一个端口，如：48376；
这个动态端口是有数量限制的，理论的上限是 65536 个，但是通常操作系统会预留一些作为系统级的端口号；
最常用的Linux供TCP动态分配的端口号范围默认是：32768~61000，即：28232个。

cat /proc/sys/net/ipv4/ip_local_port_range 查看TCP动态端口范围
netstat -anp  查看网络资源占用情况
```



## 5、解决思路

根据上文的分析可以推断出，耗尽本地端口资源的原因应该是本地连接没有 **<u>"及时”</u>** 释放，在服务 **<u>“并发量提升“</u>** 时导致资源耗尽。

查看代码，发现有两个主要的网络组件，HttpUtil、CsspClient。

**HttpUtil**：用来连接流控服务，以及非实时转写内部各个服务组件之间的网络连接；

**CsspClient**：是CSSP云存储服务提供的sdk。

通过阅读代码，两个网络组件内部都是封装的  Apache 的 **HttpClient**。



**资源占用原因**：

1. 两个组件内部都是使用的短连接，也就是每次都是new HttpClient()，无法有效利用长连接+连接池的效率优势；
2. **同时，代码中发现，获取完结果后没有关闭 HttpClient —— 这个点后续深入分析**。



查出代码问题，进行修改，上线，服务平稳运行。



## 6、实践反导理论

以上整个解决的过程，都是以程序员的视角按照编码的经验来分析和得出结论，中间很少指出明确的理论支撑。比如升温提到的 "**<u>及时</u>**"、"**<u>并发量提升</u>**" 都是不准确的经验词汇。

那以下就把问题的每个环节，来找到理论的解释。



### 6.1、首先，问题代码

```
使用短连接，同时没有主动关闭客户端HttpClient实例。

	那么是否就可以得出这些连接就永远不释放呢？

	显然不是的，因为转写服务已经持续快一年了，之前都正常，所以这些连接还是在某个时刻会被回收的。

	那么有人问，httpClient实例是在使用完后被GC回收了呀，不就是可以了吗？ 

	这个需要夯实一下基础知识，GC回收的是jvm的内存资源，和IO网络资源是两回事，后者是操作系统的工作，但是我们可以通过java代码向操作系统发送close指令来关闭IO资源。即：httpClient.close()；

	那么代码中我们没有close，操作系统又是怎么回收的呢？

后面继续分析。
```



### 6.2、然后，看看网络占用情况

```text
netstat -anp  网络占用详情
```

统计各网络状态的连接数量：

```text
netstat -n | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}'

TIME_WAIT 534
CLOSE_WAIT 12719
FIN_WAIT1 1
ESTABLISHED 2037
```

统计占用资源较多的条目

```text
netstat -n | awk '/^tcp/ {++S[$(NF-1)]} END {for(a in S){ if(S[a]>100) print a, S[a]}}'  

::ffff:172.21.191.100:8080 11641  云存储服务的网络连接数量
::ffff:172.21.161.12:28769 2080   流控服务的网络连接数量
```

由此可见云存储服务的网络连接存在大量的 **CLOSE_WAIT** 状态的连接。

那么，**CLOSE_WAIT** 状态是如何产生的呢？



### 6.3、再次，认识TCP的四次挥手

![tcp-conn](https://gss0.bdstatic.com/94o3dSag_xI4khGkpoWK1HF6hhy/baike/c0%3Dbaike116%2C5%2C5%2C116%2C38/sign=5c988baea3cc7cd9ee203c8b58684a5a/b58f8c5494eef01fca1e8886e0fe9925bc317d6f.jpg)

由上面的状态转换图可见，CLOSE_WAIT 是在双方进行完前两次握手之后服务端所处的状态。



咦，好像哪里不对？我们的服务器是作为客户端啊，怎么会有CLOSE_WAIT这个状态呢？

```text
	其实，是上面的图中"Client"、"Server"对你理解有误导。TCP是全双工的，双方都是可以收发数据的，所以任何一方都可以先发起关闭，叫做主动方；因此，CLOSE_WAIT 是被动方存在的状态。而不是客户端与服务端的概念。
```

那为什么会是服务端成为主动方先发起关闭呢？

```text
	通过之前的代码分析，我们发现代码里是没有主动关闭网络连接的，所以客户端的客户端会一直等在那里，但是又没有数据的收发了。   那如何打破僵局呢？ 作为TCP服务端会有keep-alive配置，比如15s、30s，当连接空闲达到这个值，服务端就会主动发起关闭。
```

在服务端keep-alive时间范围内，双方都处于ESTABLISHED状态，其实数据早就传传输完成了，所以双方的资源都空耗了keep-alive时间，真是犯罪啊。

前面我们提到，我们的代码没有主动发起close，但是操作系统还是在缓慢回收的，那到底是多久回收呢？

```text
cat /proc/sys/net/ipv4/tcp_keepalive_time
7200     --两个小时
```

因为，客户端的网络连接已经失去了控制，只能让操作系统来兜底。

所以，在两个小时这个时间窗口内，大量的并发请求，连接数量积压，系统端口占用超过28232个，则会出现：java.net.ConnectException: Cannot assign requested address。 这就是问题的根本原因。



同时，在服务端keep-alive时间里也一直占用着资源，如果再多一些我们这样的客户端，再多一些并发，CSSP云存储的服务就躺下了！！

**tips：**

```text
在问题排查的过程中cssp云存储那边的服务好像没啥波动，反倒是我们这边摇摇欲坠。这一度影响着我对问题的定位。
后来通过他们的开发才了解到他们的服务关闭了keep-alive长连接，因为以前出现过网络资源爆了，没有排查出原因，就关了长连接。真是骚啊！！！
```



最后，要解决这个问题，就需要在实现客户端时要充分复用网络资源高效利用连接池。或者主动关闭客户端连接。

### 6.4、最后，遗漏补充

前面我们分析了原因解决了问题，但是还有很重的东西遗漏了。那就是四次挥手，其实还没有分析完。

我们只是谈到CLOSE_WAIT是怎么来的，以及如何避免客户端失控的CLOSE_WAIT连接。

那后面呢？  四次挥手还没有完成的！  无论是主动关闭的一方还是被动的一方连接都是存在的。

刚刚我们只讲了客户端作为被动的一方进入失控的CLOSE_WAIT状态，操作系统会兜底回收。

那么主动的一方呢，比如上面的云服务器，它15s后发现这个连接没反应了，发起主动关闭，而这个时候客户端在CLOSE_WAIT状态卡住了，客户端操作系统的兜底需要两个小时，而且也不会通知服务端连接回收了，那服务端作为主动方怎么办？是否也有一个操作系统兜底的时间配置？

```text
确实是有的，从状态图可以看出，被动方在CLOSE_WAIT状态是，主动方是FIN_WAIT_2的状态。

cat /proc/sys/net/ipv4/tcp_fin_timeout
60              --60秒，也就是在FIN_WAIT_2等待60秒，操作系统就回收连接。
```



**TIPS**：

```text
	作为断开连接的主动方在完成四次挥手后，还要承担2MSL的TIME_WAIT时间消耗，作为资源紧缺的服务端也是致命的。不要让服务端来发起断开连接！！！
	
	MSL是Maximum Segment Lifetime英文的缩写，中文可以译为“报文最大生存时间”
```



## 7、总结

最后的最后，总结一下：

珍惜服务器资源；

及时回收失效的资源，不要出现让服务端来发起关闭连接，意味着网络资源已经浪费了很长一段时间了；

一定要写好网络客户端，尽量使用连接池复用网络资源，在不需要时，一定要主动关闭。